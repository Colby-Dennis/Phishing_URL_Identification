p <- c(1,2,3,4,5,6)
plot(p)
y <- c(1,1,1,1,1,1)
plot(p,y)
plot(p, numeric(length(p)))
p <- c(1:10)
plot(p, numeric(length(p)))
?vectorplot
p <- (1:10)
y <- integer(10)
plot(p,y, main="Constant velocity car")
y[4] <- 2
plot(p,y, main="Constant velocity car")
plot(p,y, main="Constant velocity car", cph="3")
?plot
plot(p,y, main="Constant velocity car", pch="3")
plot(p,y, main="Constant velocity car", pch="3")
y1 <- integer(10)
y2 <- integer(10,0.1)
y2 <- integer(10)
y2 <- y2 + 0.1
?points
p1 <- plot(p, y1, pch=20)
p2 <- plot(p, y2, pch=y2)
p2 <- plot(p, y2, pch="y2")
p2 <- plot(p, y2, pch=20, color="red")
time <- c(0:0.1:10)
time <- c(0:100)
time <- time*0.1
time(length)
length(time)
time[101]
car1_position <- time * 0.3
car2_position <- time * (-0.1) + 3
line1 <- plot(time, car1_position)
line2 <- plot(time, car2_position)
plot(line1)
plot(time, car_1position)
plot(time, car1_position)
points(car2_position)
car2_position <- time * (-0.2) + 2
points(car2_position)
plot(time, car2_position)
plot(time, car1_position, car2_position)
plot(time, car1_position)
points(car2_position, col=2)
points(time, car2_position, col=2)
install.packages(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
#install.packages("ggplot2")
library(ggplot2)
#install.packages("ggplot2")
library(ggplot)
#install.packages("ggplot2")
library(ggplot2)
install.packages("pillar")
#install.packages("ggplot2")
library(ggplot2)
time <- c(1:100) * 0.1
car1_position <- time * 0.3
car2_ position <- (time * (-0.2)) + 2
car2_ position <- (time * -0.2) + 2
car2_ position <- time * (-0.2) + 2
car2_ position <- -0.2 * time  + 2
car2_ position <- time * - 0.2
car2_ position <- time * -0.2
#install.packages("ggplot2")
library(ggplot2)
time <- c(1:100) * 0.1
car1_position <- time * 0.3
car2_ position <- time * -0.2
car1_position_final <- time * 0.1 - 2.8
car2_position_final <- time * 0.1 - 3
time * -1
car2_ position <- time * -1
car2_position <- time * -0.2
car2_position <- time * -0.2 + 2
car1_p <- num(101)
car1_p <- numeric(101)
car1_p <- numeric(101)
car2_p <- numeric(101)
car1_v <- numeric(101)
car2_v <- numeric(101)
car1_p[:39] <- car1_position[:39]
car1_p[1:39] <- car1_position[1:39]
car1_p_f[40:101] <- car1_position_final[40:101]
car1_p[40:101] <- car1_position_final[40:101]
car2_p[1:39] <- car2_position[1:39]
car2_p[40:101] <- car2_position_final[40:101]
plot(time,car1_p)
length(car1_p)
length(time)
time <- c(0:100) * 0.1
car1_position <- time * 0.3
car2_position <- time * -0.2 + 2
car1_position_final <- time * 0.1 - 2.8
car2_position_final <- time * 0.1 - 3
car1_p <- numeric(101)
car2_p <- numeric(101)
car1_v <- numeric(101)
car2_v <- numeric(101)
car1_p[1:39] <- car1_position[1:39]
car1_p[40:101] <- car1_position_final[40:101]
car2_p[1:39] <- car2_position[1:39]
car2_p[40:101] <- car2_position_final[40:101]
plot(time,car1_p)
car1_position_final <- time * 0.1 - 0.8
car2_position_final <- time * 0.1 - 1
car1_p[40:101] <- car1_position_final[40:101]
car2_p[40:101] <- car2_position_final[40:101]
plot(time,car1_p)
car1_position_final <- time * 0.1 + 0.8
car2_position_final <- time * 0.1 + 1
car1_p[40:101] <- car1_position_final[40:101]
car2_p[40:101] <- car2_position_final[40:101]
plot(time,car1_p)
car1_position_final <- time * 0.1 + 0.7
car2_position_final <- time * 0.1 + 0.9
car1_position_final <- time * 0.1 + 0.7
car2_position_final <- time * 0.1 + 0.8
car1_p[40:101] <- car1_position_final[40:101]
car2_p[1:39] <- car2_position[1:39]
car2_p[40:101] <- car2_position_final[40:101]
plot(time,car1_p)
car1_position_final <- time * 0.1 + 0.8
car2_position_final <- time * 0.1 + 0.9
car1_p <- numeric(101)
car2_p <- numeric(101)
car1_v <- numeric(101)
car2_v <- numeric(101)
car1_p[1:39] <- car1_position[1:39]
car1_p[40:101] <- car1_position_final[40:101]
car2_p[1:39] <- car2_position[1:39]
car2_p[40:101] <- car2_position_final[40:101]
plot(time,car1_p)
car1_position_final <- time * 0.1 + 0.75
car1_p[40:101] <- car1_position_final[40:101]
plot(time,car1_p)
car2_position_final <- time * 0.1 + 0.8
car2_p[1:39] <- car2_position[1:39]
car2_p[40:101] <- car2_position_final[40:101]
points(time,car2_p, col="2")
car2_position <- time * -0.2 + 1.9
car2_p[1:39] <- car2_position[1:39]
points(time,car2_p, col="2")
#install.packages("ggplot2")
library(ggplot2)
time <- c(0:100) * 0.1
car1_position <- time * 0.3
car2_position <- time * -0.2 + 1.9
car1_position_final <- time * 0.1 + 0.75
car2_position_final <- time * 0.1 + 0.8
car1_p <- numeric(101)
car2_p <- numeric(101)
car1_v <- numeric(101)
car2_v <- numeric(101)
car1_p[1:39] <- car1_position[1:39]
car1_p[40:101] <- car1_position_final[40:101]
car2_p[1:39] <- car2_position[1:39]
car2_p[40:101] <- car2_position_final[40:101]
plot(time,car1_p)
points(time,car2_p, col="2")
c1_v[1:39] <- 0.3
car1_v <- numeric(101)
car2_v <- numeric(101)
car1_v[1:39] <- 0.3
car2_v[1:39] <- -0.2
car1_v[40:101] <- 0.1
car2_v[40:101] <- 0.1
plot(time,car1_p, main="Position vs Time", xlab="Time(s)", ylab="Position(m)")
points(time,car2_p, col="2")
plot(time, car1_v, main="Velocity vs Time", xlab="Time(s)", ylab="Velocity(m/s)")
points(time, car2_v, col="2")
df <- data.frame(time, car1_p, car2_p, car1_v, car2_v)
my_names <- c("Time (s)", "Car 1 Position (m)", "Car 2 Position (m)",
"Car 1 Velocity (m/s)", "Car 2 Velocity (m/s)")
names(df) <- my_names
View(df)
write.csv(df, "two_car_motion.csv")
getwd()
library(caret)
library(lsa)
set.seed(700)
## Cosine Distance function
cosine_dist <- function(test_set, train_set){
row_num<-nrow(test_set)
col_num<-nrow(train_set)
result = matrix(0,row_num,col_num)
for (i in 1:row_num)
{
for (j in 1:col_num)
{
result[i,j] = 1 - cosine(as.numeric(train_set[j,]),as.numeric(test_set[i,]))
# result[i,j] =
}
}
return(result)
}
# Regular KNN test
mysmalldata_train <- read.delim(file.choose(), header = T, , stringsAsFactor = FALSE, sep = ",")
mysmalldata_test <-  read.delim(file.choose(), header = T, , stringsAsFactor = FALSE, sep = ",")
# KNN Model
mysmalldata_train$Result<-as.factor(mysmalldata_train$Result)
mysmalldata_test$Result<-as.factor(mysmalldata_test$Result)
#x_train<-train_set[,c(2:(cols - 1))]
cols <- ncol(mysmalldata_train)
cols1 <- ncol(mysmalldata_test)
mysmalldata_train <- mysmalldata_train[,c(2:cols)]
#mysmalldata_train
mysmalldata_test < mysmalldata_test[,c(2:cols1)]
grid <- expand.grid(k = c(1:10))
# choose values for K in K-NN
trctl <- trainControl("repeatedcv", number = 10, repeats = 3)
knn_fit_small <- train(Result ~., data = mysmalldata_train, method = "knn",trControl=trctl, tuneGrid=grid)
library(caret)
install.packages("ggplot2")
library(caret)
install.packages("pillar")
install.packages("ggplot2")
library(caret)
install.packages("devtools")
devtools::install_github("r-lib/pillar")
library(caret)
install.packages("rlang")
library(caret)
devtools::install_github("r-lib/pillar")
devtools::install_github("r-lib/pillar")
remove.packages("rlang")
setwd("C:\Users\Colby\OneDrive\Documents\GitHub")
setwd("C:/Users/Colby/OneDrive/Document/itHub")
setwd("C:/Users/Colby/OneDrive/Document/GitHub")
getwd()
setwd("Github/Phishing_URL_Identification")
mysmalldata_train <- read.csv("3factors_train.csv",header=T) # 89.52%, C.50
mysmalldata_test <- read.csv("3factors_test.csv",header=T)
mysmalldata_train <- read.csv("4factors_train.csv",header=T) # 89.52%
mysmalldata_test <- read.csv("4factors_test.csv",header=T)
mysmalldata_train <- read.csv("5factors_train.csv",header=T) # 90.75%
mysmalldata_test <- read.csv("5factors_test.csv",header=T)
mysmalldata_train <- read.csv("6factors_train.csv",header=T) # 89.52%
mysmalldata_test <- read.csv("6factors_test.csv",header=T)
mysmalldata_train <- read.csv("7factors_train.csv",header=T) # 89.52%
mysmalldata_test <- read.csv("7factors_test.csv",header=T)
mysmalldata_train <- read.csv("8factors_train.csv",header=T) # 89.52%
mysmalldata_test <- read.csv("8factors_test.csv",header=T)
mysmalldata_train <- read.csv("9factors_train.csv",header=T) # 89.52%
mysmalldata_test <- read.csv("9factors_test.csv",header=T)
View(mysmalldata_test)
# Required Packages
# install.packages("ggplot2")
# install.packages("gridExtra")
# install.packages("neuralnet")
# install.packages("caret")
# install.packages("corrplot")
# install.packages("microbenchmark")
library(ggplot2)
library(gridExtra)
library(neuralnet)
library(caret)
library(rpart); library(rpart.plot)
library(DMwR)
library(corrplot)
library(microbenchmark)
#Loading in the data
mysmalldata <- read.csv("https://raw.githubusercontent.com/PhysikerWT/Phishing_URL_Identification/master/rawDataSetSmall.csv")
myrawdata <- read.csv("https://raw.githubusercontent.com/PhysikerWT/Phishing_URL_Identification/master/rawDataSet.csv", stringsAsFactors = F)
# Renaming data according to provided paper.
data_names <- c("id","having_IP_address","URL_Length","Shortining_Service","having_At_Symbol",
"double_slash_redirecting","Prefix_Suffix","having_Sub_Domain","SSLfinal_State",
"Domain_registration_length","Favicon","Port","HTTPS_token","Request_URL",
"URL_of_Anchor","Links_in_tags","SFH","Submitting_to_email","Abnormal_URL",
"Redirect","on_mouseover","RightClick","popUpWindow","Iframe","age_of_domain",
"DNSRecord","web_traffic","Page_Rank","Google_Index","Links_pointing_to_page",
"Statistical_report","Result")
names(mysmalldata) <- data_names
names(myrawdata) <- data_names
# Function that removes all non-existance result rows
clean_results <- function(df) {
does_exist <- c() # Initialize with information
i <- 1
while (i <= (nrow(df))) {
if (is.na(df[i,ncol(df)])) {
does_exist[i] <- F
} else {
does_exist[i] <- T
}
i <- i + 1
}
return(df[does_exist,])
}
# Function that replaces all NA's with zeros
replace_zero <- function(df) {
i <- 2
while (i <= (ncol(df)-1)) {
j <- 1
while (j<= nrow(df[i])) {
if (is.na(df[[i]][j])) {
df[[i]][j] <- 0
}
j <- j + 1
}
i <- i + 1
}
return(df)
}
# Parallelized replace NA w/ zero
replace_zero_new <- function(df) {
i <- 2
while (i <= (ncol(df)-1)) {
df[[i]][is.na(df[[i]])] <- 0
i <- i + 1
}
return(df)
}
# Function that replaces the unknown with an average.
replace_average <- function(df) {
i <- 2
while (i <= (ncol(df)-1)) {
j <- 1
average = mean(df[,i], na.rm=T)
while (j<= nrow(df[i])) {
if (is.na(df[[i]][j])) {
df[[i]][j] <- average
}
j <- j + 1
}
i <- i + 1
}
return(df)
}
replace_distribution <- function(df) {
for (i in 2:(ncol(df)-1)) {
uniq1 <- c(0,-1, 1)
cnt <- tabulate(match(df[,i], uniq1))
prop <- cnt[2] / cnt[3]
for (j in 1:nrow(df)){
if(is.na(df[j,i])){
df[j,i] <-ifelse(runif(1)<=prop,-1,1)
}
}
}
return(df)
}
# Function that replaces the unknown with the most often
replace_mode <- function(df) {
i <- 2
while (i <= (ncol(df)-1)) {
j <- 1
value_matrix <- matrix(table(df[,i]))
value <- -1
if (nrow(value_matrix) == 3) {
if (value_matrix[1] > value_matrix[2] && value_matrix[1] > value_matrix[3]) {
value <- -1
} else if (value_matrix[2] > value_matrix[3]) {
value <- 0
} else {
value <- 1
}
} else {
if (value_matrix[1] > value_matrix[2]) {
value <- -1
} else {
value <- 1
}
}
while (j<= nrow(df[i])) {
if (is.na(df[[i]][j])) {
df[[i]][j] <- value
}
j <- j + 1
}
i <- i + 1
}
return(df)
}
#Randomly generates either a -1,0,1
set0<-c(-1,0,1)
replace_random_withzero <- function(df) {
i <- 2
while (i <= (ncol(df)-1)) {
j <- 1
while (j<= nrow(df[i])) {
if (is.na(df[[i]][j])) {
value<-sample(set0,1)
df[[i]][j] <- value
}
j <- j + 1
}
i <- i + 1
}
return(df)
}
# A function to covert predictions to binary result
get_prediction <- function(mod) {
result_vec <- integer(nrow(mod))
i <- 1
while (i <= nrow(mod)) {
if (mod[i] >= 0) {
result_vec[i] <- 1
} else {
result_vec[i] <- -1
}
i <- i + 1
}
return(result_vec)
}
set.seed(700)
# Getting datasets
small_cleaned_results <- clean_results(mysmalldata)
raw_cleaned_results <- clean_results(myrawdata)
# Partition Data
partitioned_small <- createDataPartition(y = small_cleaned_results$Result, p= 0.3, list = FALSE)
# Required Packages
# install.packages("ggplot2")
# install.packages("gridExtra")
# install.packages("neuralnet")
# install.packages("caret")
# install.packages("corrplot")
# install.packages("microbenchmark")
library(ggplot2)
library(gridExtra)
library(neuralnet)
library(caret)
library(rpart); library(rpart.plot)
library(DMwR)
library(corrplot)
library(microbenchmark)
set.seed(700)
# Getting datasets
small_cleaned_results <- clean_results(mysmalldata)
raw_cleaned_results <- clean_results(myrawdata)
# Partition Data
partitioned_small <- createDataPartition(y = small_cleaned_results$Result, p= 0.3, list = FALSE)
install.packages('ggplot2')
library(ggplot2)
mysmalldata__train <- read.csv("javascript_train.csv", header=T)
mysmalldata_test <- read.csv("javascript_test.csv", header=T)
# Decision Tree
tree.model <- rpart(Result~., data=mysmalldata_train, method="class")
print(tree.model) #shows the data partition percentages and the split attributes
#run the model on the data, print a confusion matrix, and show the accuracy
tree.prediction <- predict(tree.model, newdata=mysmalldata_test, type="class")
mysmalldata__train <- read.csv("javascript_train.csv", header=T)
mysmalldata_test <- read.csv("javascript_test.csv", header=T)
# Decision Tree
tree.model <- rpart(Result~., data=mysmalldata_train, method="class")
print(tree.model) #shows the data partition percentages and the split attributes
#run the model on the data, print a confusion matrix, and show the accuracy
tree.prediction <- predict(tree.model, newdata=mysmalldata_test, type="class")
confusion.matrix <- table(mysmalldata_test$Result, tree.prediction)
mysmalldata_train <- read.csv("javascript_train.csv", header=T)
mysmalldata_test <- read.csv("javascript_test.csv", header=T)
# Decision Tree
tree.model <- rpart(Result~., data=mysmalldata_train, method="class")
print(tree.model) #shows the data partition percentages and the split attributes
#run the model on the data, print a confusion matrix, and show the accuracy
tree.prediction <- predict(tree.model, newdata=mysmalldata_test, type="class")
confusion.matrix <- table(mysmalldata_test$Result, tree.prediction)
print(confusion.matrix)
#generate the tree accuracy from the confusion matrix
accuracy.percent <- 100*sum(diag(confusion.matrix))/sum(confusion.matrix)
print(paste("accuracy:",accuracy.percent,"%"))
print(paste("error rate:",100-accuracy.percent,"%"))
#plot the tree
plot(tree.model)
text(tree.model, pretty=1)
prettyTree(tree.model)
rpart.plot(tree.model,box.palette="RdBu", shadow.col="gray", nn=TRUE)
mysmalldata_train <- read.csv("javascript_train.csv", header=T)[,-1]
mysmalldata_test <- read.csv("javascript_test.csv", header=T)[,-1]
View(mysmalldata_test)
# Decision Tree
tree.model <- rpart(Result~., data=mysmalldata_train, method="class")
print(tree.model) #shows the data partition percentages and the split attributes
#run the model on the data, print a confusion matrix, and show the accuracy
tree.prediction <- predict(tree.model, newdata=mysmalldata_test, type="class")
confusion.matrix <- table(mysmalldata_test$Result, tree.prediction)
print(confusion.matrix)
#generate the tree accuracy from the confusion matrix
accuracy.percent <- 100*sum(diag(confusion.matrix))/sum(confusion.matrix)
print(paste("accuracy:",accuracy.percent,"%"))
print(paste("error rate:",100-accuracy.percent,"%"))
#plot the tree
plot(tree.model)
text(tree.model, pretty=1)
prettyTree(tree.model)
rpart.plot(tree.model,box.palette="RdBu", shadow.col="gray", nn=TRUE)
library(C50)
mysmalldata_train$Result<-as.factor(mysmalldata_train$Result) ###FIXED THIS LINE
c5tree.model <- C5.0(as.formula(Result~.),data=mysmalldata_train, rules=T)
str(mysmalldata_train$Result)
print(c5tree.model)
summary(c5tree.model)
#run the model on the data, print a confusion matrix, and show the accuracy
c5tree.prediction <- predict(c5tree.model, newdata=mysmalldata_test)
c5confusion.matrix <- table(mysmalldata_test$Result, c5tree.prediction)
print(c5confusion.matrix)
accuracy.percent <- 100*sum(diag(c5confusion.matrix))/sum(c5confusion.matrix)
print(paste("accuracy:",accuracy.percent,"%"))
#plot the tree (have to rerun the model with rules=F)
c5tree.model <- C5.0(as.formula(Result~.), data=mysmalldata_train, rules=F)
plot(c5tree.model)
